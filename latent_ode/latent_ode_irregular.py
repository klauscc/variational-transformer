# -*- coding: utf-8 -*-
"""spiral_odenet_mytest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sH2cz26nPKolxjquPKZaTSDZQtR2_oc9
"""
import os
import argparse
import logging
import time
import numpy as np
import numpy.random as npr
import matplotlib
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import pickle as pkl

parser = argparse.ArgumentParser()
parser.add_argument('--adjoint', type=eval, default=False)
parser.add_argument('--visualize', type=eval, default=True)
parser.add_argument('--niters', type=int, default=2000)
parser.add_argument('--lr', type=float, default=0.01)
parser.add_argument('--gpu', type=int, default=0)
parser.add_argument('--train_dir', type=str, default=None)
args = parser.parse_args(args=[])

if args.adjoint:
    from torchdiffeq import odeint_adjoint as odeint
else:
    from torchdiffeq import odeint

from latent_ode_trans.modules import TransformerLayer

#%%
def generate_spiral2d(
        nspiral=1000,
        ntotal=500,
        nsample=100,
        start=0.,
        stop=1,    # approximately equal to 6pi
        noise_std=.1,
        a=0.,
        b=1.,
        irregular=False, 
        savefig=True,
        save_path="./spiral.pkl"):
    """Parametric formula for 2d spiral is `r = a + b * theta`.

    Args:
      nspiral: number of spirals, i.e. batch dimension
      ntotal: total number of datapoints per spiral
      nsample: number of sampled datapoints for model fitting per spiral
      start: spiral starting theta value
      stop: spiral ending theta value
      noise_std: observation noise standard deviation
      a, b: parameters of the Archimedean spiral
      irregular: False for evenly distributed timepoints
      savefig: plot the ground truth for sanity check

    Returns: 
      Tuple where first element is true trajectory of size (nspiral, ntotal, 2),
      second element is noisy observations of size (nspiral, nsample, 2),
      third element is timestamps of size (ntotal,),
      and fourth element is timestamps of size (nsample,)
    """
    #if os.path.isfile(save_path):
    #    return pkl.load(open(save_path, 'rb'))

    # add 1 all timestamps to avoid division by 0
    orig_ts = np.linspace(start, stop, num=ntotal)
    if irregular == True:
      samp_t = np.sort(npr.permutation(333)[:nsample])
      inward_t = np.linspace(-1, -100, 100).astype(np.int16) # inward
      outward_t = np.linspace(333, 432, 100).astype(np.int16) # ourward
      samp_ts = orig_ts[samp_t]
      inward_ts = - orig_ts[1:101]
      outward_ts = orig_ts[outward_t] 
    else:    
      samp_ts = orig_ts[:nsample]
      inward_ts = orig_ts[nsample: 2 * nsample]
    
    # generate clock-wise and counter clock-wise spirals in observation space
    # with two sets of time-invariant latent dynamics
    zs_cw = stop + 1. - orig_ts
    rs_cw = a + b * 50. / zs_cw
    xs, ys = rs_cw * np.cos(zs_cw) - 5., rs_cw * np.sin(zs_cw)
    orig_traj_cw = np.stack((xs, ys), axis=1)

    zs_cc = orig_ts
    rw_cc = a + b * zs_cc
    xs, ys = rw_cc * np.cos(zs_cc) + 5., rw_cc * np.sin(zs_cc)
    orig_traj_cc = np.stack((xs, ys), axis=1)

    if savefig:
        plt.figure()
        plt.plot(orig_traj_cw[:, 0], orig_traj_cw[:, 1], label='clock')
        plt.plot(orig_traj_cc[:, 0], orig_traj_cc[:, 1], label='counter clock')
        plt.legend()
        plt.savefig('./ground_truth.png', dpi=500)
        print('Saved ground truth spiral at {}'.format('./ground_truth.png'))

    # sample starting timestamps
    orig_trajs = []
    samp_trajs = []
    samp_trajs_nonoise = []
    inward_trajs = []
    outward_trajs = []

    for _ in range(nspiral):
        cc = bool(npr.rand() > .5)    # uniformly select rotation
        orig_traj = orig_traj_cc if cc else orig_traj_cw
        orig_trajs.append(orig_traj)

        if irregular == True:
          t0_idx = npr.multinomial(1, [1. / (667 - 2 * nsample)] * (667 - 2 * nsample))
          t0_idx = np.argmax(t0_idx) + nsample
          #t0_idx = min(ntotal - 2 * nsample, t0_idx) + nsample
          #t0_idx = 666

          samp_traj = orig_traj[samp_t + t0_idx, :].copy() # samp_t - samp_t[0] + t0_idx
          samp_trajs_nonoise.append(samp_traj.copy())
          samp_traj += npr.randn(*samp_traj.shape) * noise_std
          samp_trajs.append(samp_traj)

          inward_traj = orig_traj[inward_t + t0_idx, :].copy()
          inward_trajs.append(inward_traj)

          outward_traj = orig_traj[outward_t + t0_idx, :].copy()
          outward_trajs.append(outward_traj)


        else:
          t0_idx = npr.multinomial(1, [1. / (ntotal - 2. * nsample)] * (ntotal - int(2 * nsample)))
          t0_idx = np.argmax(t0_idx) + nsample
          t0_idx = min(ntotal - 2 * nsample, t0_idx)

          samp_traj = orig_traj[t0_idx:t0_idx + nsample, :].copy()
          samp_trajs_nonoise.append(samp_traj.copy())
          samp_traj += npr.randn(*samp_traj.shape) * noise_std
          samp_trajs.append(samp_traj)

          inward_traj = orig_traj[t0_idx + nsample:t0_idx + 2 * nsample, :].copy()
          inward_trajs.append(inward_traj)

    # batching for sample trajectories is good for RNN; batching for original
    # trajectories only for ease of indexing
    orig_trajs = np.stack(orig_trajs, axis=0)
    samp_trajs = np.stack(samp_trajs, axis=0)
    samp_trajs_nonoise = np.stack(samp_trajs_nonoise, axis=0)
    inward_trajs = np.stack(inward_trajs, axis=0)
    outward_trajs = np.stack(outward_trajs, axis=0)

    data = orig_trajs, samp_trajs, samp_trajs_nonoise, inward_trajs, outward_trajs, orig_ts, samp_ts, inward_ts, outward_ts
    pkl.dump(data, open(save_path, 'wb'))
    return data
#%%
# visualization of spiral curves
orig_trajs, samp_trajs, samp_trajs_nonoise, inward_trajs, outward_trajs, orig_ts, samp_ts, inward_ts, outward_ts = generate_spiral2d(
        nspiral=10, ntotal=1000,start=0, stop=6*np.pi, noise_std=.3, a=0, b=.3, irregular=True, savefig=False)
plt.figure(); plt.plot(orig_trajs[0, :, 0], orig_trajs[0, : , 1], label = 'ground truth spiral'); plt.plot(samp_trajs[0, :, 0], samp_trajs[0, : , 1], 'r.', label = 'sampled data')
plt.plot(samp_trajs_nonoise[0, :, 0], samp_trajs_nonoise[0, : , 1], 'y.', label = 'sampled data no noise');
plt.plot(inward_trajs[0, :, 0], inward_trajs[0, : , 1], 'g.', label = 'inward data'); plt.plot(outward_trajs[0, :, 0], outward_trajs[0, : , 1], 'g.', label = 'outward data')
plt.legend(); plt.show()
#%%
class LatentODEfunc(nn.Module):
    
    def __init__(self, latent_dim=4, nhiiden=20):
        super(LatentODEfunc, self).__init__()
        self.elu = nn.ELU(inplace=True)
        self.fc1 = nn.Linear(latent_dim, nhidden)
        self.fc2 = nn.Linear(nhidden, nhidden)
        self.fc3 = nn.Linear(nhidden, latent_dim)
        self.nfe = 0
        
    def forward(self, t, x):
        self.nfe += 1
        out = self.fc1(x)
        out = self.elu(out)
        out = self.fc2(out)
        out = self.elu(out)
        out = self.fc3(out)
        return out
    
class RecognitionRNN(nn.Module):
    
    def __init__(self, latent_dim=4, obs_dim=2, nhidden=25, nbatch=1):
        super(RecognitionRNN, self).__init__()
        self.nhidden = nhidden
        self.nbatch = nbatch
        self.i2h = nn.Linear(obs_dim + nhidden, nhidden)
        self.h2o = nn.Linear(nhidden, latent_dim*2)
        
    def forward(self, x, h):
        combined = torch.cat((x,h), dim=1)
        h = torch.tanh(self.i2h(combined))
        out = self.h2o(h)
        return out, h
    
    def initHidden(self):
        return torch.zeros(self.nbatch, self.nhidden)
    
class Decoder(nn.Module):
    
    def __init__(self, latent_dim=4, obs_dim=2, nhidden=20):
        super(Decoder, self).__init__()
        self.relu = nn.ReLU(inplace=True)
        self.fc1 = nn.Linear(latent_dim, nhidden)
        self.fc2 = nn.Linear(nhidden, obs_dim)
        
    def forward(self, z):
        out = self.fc1(z)
        out = self.relu(out)
        out = self.fc2(out)
        return out

class RunningAverageMeter(object):
    """Computes and stores the average and current value"""

    def __init__(self, momentum=0.99):
        self.momentum = momentum
        self.reset()

    def reset(self):
        self.val = None
        self.avg = 0
        self.hist = []

    def update(self, val):
        if self.val is None:
            self.avg = val
        else:
            self.avg = self.avg * self.momentum + val * (1 - self.momentum)
        self.val = val
        self.hist.append(val)


def log_normal_pdf(x, mean, logvar):
    const = torch.from_numpy(np.array([2. * np.pi])).float().to(x.device)
    const = torch.log(const)
    return -.5 * (const + logvar + (x - mean) ** 2. / torch.exp(logvar))


def normal_kl(mu1, lv1, mu2, lv2):
    v1 = torch.exp(lv1)
    v2 = torch.exp(lv2)
    lstd1 = lv1 / 2.
    lstd2 = lv2 / 2.

    kl = lstd2 - lstd1 + ((v1 + (mu1 - mu2) ** 2.) / (2. * v2)) - .5
    return kl

#%%
ROOT_FOLDER = '/home/nel/Code/class/variational-transformer/data'
import datetime,time, os
ts = time.time()
ct = datetime.datetime.fromtimestamp(ts).strftime('%Y%m%d_%H%M')
path = os.path.join(ROOT_FOLDER, ct)
try:
    os.mkdir(path)
    os.mkdir(os.path.join(path, 'ode'))
    os.mkdir(os.path.join(path, 'transformer'))
    print(f'make folder:{path}')
except:
    print('already exist') 
    
#%%
# generate toy spiral data
nspiral = 1000
start = 0
stop = 6*np.pi
noise_std = .1
a = 0.
b = .3
ntotal = 1000
nsample = 100
irregular = True
data_path = os.path.join(path, 'data.pkl')

data = generate_spiral2d(nspiral=nspiral, ntotal=ntotal,start=start, stop=stop, noise_std=noise_std, a=a, b=b, irregular=irregular, savefig=False, save_path=data_path)
orig_trajs, samp_trajs, samp_trajs_nonoise, inward_trajs, outward_trajs, orig_ts, samp_ts, inward_ts, outward_ts = data
plt.figure(); plt.plot(orig_trajs[0, :, 0], orig_trajs[0, : , 1], label = 'ground truth spiral'); plt.plot(samp_trajs[0, :, 0], samp_trajs[0, : , 1], 'r.', label = 'sampled data')
plt.plot(samp_trajs_nonoise[0, :, 0], samp_trajs_nonoise[0, : , 1], 'y.', label = 'sampled data no noise');
plt.plot(inward_trajs[0, :, 0], inward_trajs[0, : , 1], 'g.', label = 'inward data'); plt.plot(outward_trajs[0, :, 0], outward_trajs[0, : , 1], 'g.', label = 'outward data')
plt.legend(); plt.show()


#%%
for transformer in [False, True]:
    for path in ['/home/nel/Code/class/variational-transformer/data/20210317_2253', 
                 '/home/nel/Code/class/variational-transformer/data/20210317_2256',
                 '/home/nel/Code/class/variational-transformer/data/20210317_2026']:    
        data_path = os.path.join(path, 'data.pkl')
        data = pkl.load(open(data_path, 'rb'))
        orig_trajs, samp_trajs, samp_trajs_nonoise, inward_trajs, outward_trajs, orig_ts, samp_ts, inward_ts, outward_ts = data
        
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f'use cuda: {torch.cuda.is_available()}')
        
        orig_trajs = torch.from_numpy(orig_trajs).float().to(device)
        samp_trajs = torch.from_numpy(samp_trajs).float().to(device)
        samp_trajs_nonoise = torch.from_numpy(samp_trajs_nonoise).float().to(device)
        inward_trajs = torch.from_numpy(inward_trajs).float().to(device)
        outward_trajs = torch.from_numpy(outward_trajs).float().to(device)
        samp_ts = torch.from_numpy(samp_ts).float().to(device)
        inward_ts = torch.from_numpy(inward_ts).float().to(device)
        outward_ts = torch.from_numpy(outward_ts).float().to(device)
        
        #%%
        # input parameters
        latent_dim = 2
        nhidden = 20
        rnn_nhidden = 25
        obs_dim = 2
        niters = 15000
        print_iter = 20
        lr = 0.01
        itr=0
        
        if not transformer:
            save_path = os.path.join(path, 'ode')
        else:
            save_path = os.path.join(path, 'transformer')
        print(save_path)
        
        #%%
        # model
        if not transformer:
            func = LatentODEfunc(latent_dim, nhidden).to(device)
            rec = RecognitionRNN(latent_dim, obs_dim, rnn_nhidden, nspiral).to(device)
            dec = Decoder(latent_dim, obs_dim, nhidden).to(device)
            params = (list(func.parameters()) + list(dec.parameters()) + list(rec.parameters()))
            optimizer = optim.Adam(params, lr=lr)
        else:
            func = LatentODEfunc(latent_dim, nhidden).to(device)
            rec = TransformerLayer(latent_dim * 2, obs_dim, nhidden, dropout=0).to(device)
            dec = Decoder(latent_dim, obs_dim, nhidden).to(device)
            params = (list(func.parameters()) + list(dec.parameters()) + list(rec.parameters()))
            optimizer = optim.Adam(params, lr=lr)
            
        loss_meter = RunningAverageMeter()
        rmse_train = []
        rmse_inward = []
        rmse_outward = []
          
        #%%    
        for itr in range(itr+1, niters + itr + 1):
            optimizer.zero_grad()    
            #scheduler.step()
            if not transformer:
                # backward in time to infer q(z_0)
                h = rec.initHidden().to(device)
                for t in reversed(range(samp_trajs.size(1))):
                    obs = samp_trajs[:, t, :]
                    out, h = rec.forward(obs, h)
                qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]
            else:
                rec.train()
                dec.train()
                # backward in time to infer q(z_0)
                out = rec.forward(samp_trajs, samp_ts)    # (bs, nsample, latent_dim*2)
                qz0_mean, qz0_logvar = out[:, 0, :latent_dim], out[:, 0, latent_dim:]
            epsilon = torch.randn(qz0_mean.size()).to(device)
            z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean
        
            # forward in time and solve ode for reconstructions
            pred_z = odeint(func, z0, samp_ts).permute(1, 0, 2)
            pred_x = dec(pred_z)
        
            # compute loss
            noise_std_ = torch.zeros(pred_x.size()).to(device) + noise_std
            noise_logvar = 2. * torch.log(noise_std_).to(device)
            logpx = log_normal_pdf(samp_trajs, pred_x, noise_logvar).sum(-1).sum(-1)
            pz0_mean = pz0_logvar = torch.zeros(z0.size()).to(device)
            analytic_kl = normal_kl(qz0_mean, qz0_logvar, pz0_mean, pz0_logvar).sum(-1)
            loss = torch.mean(-logpx + analytic_kl, dim=0)
            loss.backward()
            optimizer.step()
            loss_meter.update(loss.item())
        
            with torch.no_grad():
                test_z = odeint(func, z0, inward_ts).permute(1, 0, 2)    # (bs, nsample+1, nc)
                test_x = dec(test_z[:, :, :])    # (bs, nsample, nc)
                rmse = torch.sqrt(torch.mean((test_x - inward_trajs)**2))
                rmse = rmse.item()
                rmse_inward.append([itr, rmse])
                
                test_z = odeint(func, z0, outward_ts).permute(1, 0, 2)    # (bs, nsample+1, nc)
                test_x = dec(test_z[:, :, :])    # (bs, nsample, nc)
                rmse1 = torch.sqrt(torch.mean((test_x - outward_trajs)**2))
                rmse1 = rmse1.item()
                rmse_outward.append([itr, rmse1])
        
                train_rmse = torch.sqrt(torch.mean((pred_x - samp_trajs_nonoise)**2))
                train_rmse = train_rmse.item()
                rmse_train.append([itr, train_rmse])
                
            if (itr % print_iter) == 0:
                print('Iter: {}, running avg elbo: {:.4f}. train_rmse: {:.4f}. test_inward_rmse: {:.4f}. test_outward_rmse: {:.4f}'.format(itr, -loss_meter.avg, train_rmse, rmse, rmse1))
                #print(f'Learning rate {optimizer.param_groups[0]["lr"]}')
                #print('Iter: {:4d}, running elbo: {:.4f}'.format(itr, -loss_meter.val))
         
            if (itr % 1000) == 0:
                # saving the loss and parameters
                ckpt_path = os.path.join(save_path, f'ckpt_{itr}.pth')
                torch.save({
                    'func_state_dict': func.state_dict(),
                    'rec_state_dict': rec.state_dict(),
                    'dec_state_dict': dec.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'orig_trajs': orig_trajs,
                    'samp_trajs': samp_trajs,
                    'orig_ts': orig_ts,
                    'samp_ts': samp_ts,
                    'inward_ts': inward_ts,
                    'outward_ts': outward_ts,
                    'loss_hist': loss_meter.hist,
                    'rmse_train':rmse_train,
                    'rmse_inward':rmse_inward,
                    'rmse_outward':rmse_outward
                    }, ckpt_path)
                
                plt.figure(figsize=(25,20))
                a = 0
                i_range = [a, a+6]
                for idx in range(1, 7):
                  with torch.no_grad():
                    if not transformer:
                        # sample from trajectorys' approx. posterior
                        h = rec.initHidden().to(device)
                        for t in reversed(range(samp_trajs.size(1))):
                            obs = samp_trajs[:, t, :]
                            out, h = rec.forward(obs, h)
                        qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]
                    else:
                        rec.eval()
                        dec.eval()
                        out = rec.forward(samp_trajs, samp_ts)    # (bs, nsample, latent_dim*2)
                        qz0_mean, qz0_logvar = out[:, 0, :latent_dim], out[:, 0, latent_dim:]
                    epsilon = torch.randn(qz0_mean.size()).to(device)
                    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean
                
                    # take first trajectory for visualization
                    i = idx + a
                    z0 = z0[i]
                
                    ts_pos = np.linspace(0., 4. * np.pi, num=1000)
                    ts_neg = np.linspace(-2*np.pi, 0., num=1000)[::-1].copy()
                    ts_pos = torch.from_numpy(ts_pos).float().to(device)
                    ts_neg = torch.from_numpy(ts_neg).float().to(device)
                
                    zs_pos = odeint(func, z0, ts_pos)
                    zs_neg = odeint(func, z0, ts_neg)
                
                    xs_pos = dec(zs_pos)
                    xs_neg = torch.flip(dec(zs_neg), dims=[0])
                
                  xs_pos = xs_pos.cpu().numpy()
                  xs_neg = xs_neg.cpu().numpy()
                  orig_traj = orig_trajs[i].cpu().numpy()
                  samp_traj = samp_trajs[i].cpu().numpy()
                
                  plt.subplot(2, 3, idx)
                  plt.plot(orig_traj[:, 0], orig_traj[:, 1],
                          'g', label='true trajectory')
                  plt.plot(xs_pos[:, 0], xs_pos[:, 1], 'r',
                          label='learned trajectory (t>0)')
                  plt.plot(xs_neg[:, 0], xs_neg[:, 1], 'b',
                          label='learned trajectory (t<0)')
                  plt.scatter(samp_traj[:, 0], samp_traj[
                              :, 1], label='sampled data', s=3)
                  plt.legend(loc='upper right')
                plt.savefig(os.path.join(save_path, f'{itr}_iterations_{i_range}'))

#%%
# load the loss and paramters
#itr = ?
result = {}
for path in ['/home/nel/Code/class/variational-transformer/data/20210317_1354', 
                   '/home/nel/Code/class/variational-transformer/data/20210317_1712', 
                   '/home/nel/Code/class/variational-transformer/data/20210317_2026', 
                   '/home/nel/Code/class/variational-transformer/data/20210317_2253', 
                   '/home/nel/Code/class/variational-transformer/data/20210317_2256']:
    result[path.split('/')[-1]] = {}
    for transformer in [False, True]:
        if not transformer:
            save_path = os.path.join(path, 'ode')
        else:
            save_path = os.path.join(path, 'transformer')
        print(save_path)
        files = os.listdir(save_path)
        files = sorted([file for file in files if '.pth' in file])
        flag = False; itr=15000
        while flag == False:
            if sum([str(itr) in file for file in files]) == 1:
                flag = True
                ckpt_path = os.path.join(save_path, f'ckpt_{itr}.pth')
            else:
                itr = itr - 1000
        print(ckpt_path)

        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f'use cuda: {torch.cuda.is_available()}')
        
        if not transformer:
            func = LatentODEfunc(latent_dim, nhidden).to(device)
            rec = RecognitionRNN(latent_dim, obs_dim, rnn_nhidden, nspiral).to(device)
            dec = Decoder(latent_dim, obs_dim, nhidden).to(device)
            params = (list(func.parameters()) + list(dec.parameters()) + list(rec.parameters()))
            optimizer = optim.Adam(params, lr=lr)
        else:
            func = LatentODEfunc(latent_dim, nhidden).to(device)
            rec = TransformerLayer(latent_dim * 2, obs_dim, nhidden, dropout=0).to(device)
            dec = Decoder(latent_dim, obs_dim, nhidden).to(device)
            params = (list(func.parameters()) + list(dec.parameters()) + list(rec.parameters()))
            optimizer = optim.Adam(params, lr=lr)
            
            
        loss_meter = RunningAverageMeter()
        rmse_train = []
        rmse_inward = []
        rmse_outward = []
    
        #ckpt_path = os.path.join(path, f'ckpt_{itr}.pth')
        checkpoint = torch.load(ckpt_path)
        func.load_state_dict(checkpoint['func_state_dict'])
        rec.load_state_dict(checkpoint['rec_state_dict'])
        dec.load_state_dict(checkpoint['dec_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        orig_trajs = checkpoint['orig_trajs']
        samp_trajs = checkpoint['samp_trajs']
        orig_ts = checkpoint['orig_ts']
        samp_ts = checkpoint['samp_ts']
        loss_hist = checkpoint['loss_hist']
        rmse_train = checkpoint['rmse_train']
        rmse_inward = checkpoint['rmse_inward']
        rmse_outward = checkpoint['rmse_outward']
        
        plt.figure(); plt.plot(np.array(rmse_train)[:,0], np.array(rmse_train)[:,1]); 
        plt.plot(np.array(rmse_inward)[:,0], np.array(rmse_inward)[:,1]); 
        plt.plot(np.array(rmse_outward)[:,0], np.array(rmse_outward)[:,1]); plt.xlabel('Iterations'); plt.ylabel('RMSE');plt.ylim([0, 2]);
        plt.legend(['train', 'test_inward', 'test_outward']);plt.title(path.split('/')[-1] + f'  transformer_{transformer}' ); plt.show()

        """
        summary = {}
        for idx, r in enumerate([rmse_train, rmse_inward, rmse_outward]):
            r = np.array(r)
            ii = np.where(r[:, 1] == r[:, 1].max())
            if idx == 0:
                summary['train'] = rmse_train[ii]
        """
        if not transformer:
            result[path.split('/')[-1]]['ode'] = {'train': rmse_train, 'inward': rmse_inward, 'outward': rmse_outward} 
        else:
            result[path.split('/')[-1]]['transformer'] = {'train': rmse_train, 'inward': rmse_inward, 'outward': rmse_outward} 
            
        np.save('/home/nel/Code/class/variational-transformer/data/result/result_ode_transformer.npy', result)

#%%
for mode in ['ode', 'transformer']:        
    for d in result.keys():
        summary = {}
        for idx, r in enumerate([rmse_train, rmse_inward, rmse_outward]):
            r = np.array(r)
            ii = np.where(r[:, 1] == r[:, 1].max())
            if idx == 0:
                summary['train'] = rmse_train[ii]



#%% plot the loss
loss_hist = loss_meter.hist
plt.figure(); plt.plot(range(len(loss_hist)), [-i for i in loss_hist], label = 'ODEnet'); plt.xlabel('Iterations');
plt.ylabel('ElBO'); plt.legend(); plt.show()

plt.figure(); plt.plot(range(len(loss_hist)), [-i for i in loss_hist], label = 'ODEnet');plt.xlabel('Iterations');
plt.ylabel('ElBO'); plt.ylim([-200, 0]); plt.legend(); plt.show()

plt.figure(); plt.plot(np.array(rmse_train)[:,0], np.array(rmse_train)[:,1]); 
plt.plot(np.array(rmse_inward)[:,0], np.array(rmse_inward)[:,1]); 
plt.plot(np.array(rmse_outward)[:,0], np.array(rmse_outward)[:,1]); plt.xlabel('Iterations'); plt.ylabel('RMSE');
plt.legend(['train', 'inward', 'outward']);plt.show()

#%%
# visualization
plt.figure(figsize=(25,20))
a = 0
i_range = [a, a+6]
for idx in range(1, 7):
  with torch.no_grad():
    if not transformer:
        # sample from trajectorys' approx. posterior
        h = rec.initHidden().to(device)
        for t in reversed(range(samp_trajs.size(1))):
            obs = samp_trajs[:, t, :]
            out, h = rec.forward(obs, h)
        qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]
    else:
        rec.eval()
        dec.eval()
        out = rec.forward(samp_trajs, samp_ts)    # (bs, nsample, latent_dim*2)
        qz0_mean, qz0_logvar = out[:, 0, :latent_dim], out[:, 0, latent_dim:]
    epsilon = torch.randn(qz0_mean.size()).to(device)
    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean

    # take first trajectory for visualization
    i = idx + a
    z0 = z0[i]

    ts_pos = np.linspace(0., 4. * np.pi, num=1000)
    ts_neg = np.linspace(-2*np.pi, 0., num=1000)[::-1].copy()
    ts_pos = torch.from_numpy(ts_pos).float().to(device)
    ts_neg = torch.from_numpy(ts_neg).float().to(device)

    zs_pos = odeint(func, z0, ts_pos)
    zs_neg = odeint(func, z0, ts_neg)

    xs_pos = dec(zs_pos)
    xs_neg = torch.flip(dec(zs_neg), dims=[0])

  xs_pos = xs_pos.cpu().numpy()
  xs_neg = xs_neg.cpu().numpy()
  orig_traj = orig_trajs[i].cpu().numpy()
  samp_traj = samp_trajs[i].cpu().numpy()

  plt.subplot(2, 3, idx)
  plt.plot(orig_traj[:, 0], orig_traj[:, 1],
          'g', label='true trajectory')
  plt.plot(xs_pos[:, 0], xs_pos[:, 1], 'r',
          label='learned trajectory (t>0)')
  plt.plot(xs_neg[:, 0], xs_neg[:, 1], 'b',
          label='learned trajectory (t<0)')
  plt.scatter(samp_traj[:, 0], samp_traj[
              :, 1], label='sampled data', s=3)
  plt.legend(loc='upper right')
#plt.savefig(os.path.join(path, f'{itr}_iterations_{i_range}'))

#%%
  
  
  
#%%
with torch.no_grad():
    # sample from trajectorys' approx. posterior
    h = rec.initHidden().to(device)
    for t in reversed(range(samp_trajs.size(1))):
        obs = samp_trajs[:, t, :]
        out, h = rec.forward(obs, h)
    qz0_mean, qz0_logvar = out[:, :latent_dim], out[:, latent_dim:]
    epsilon = torch.randn(qz0_mean.size()).to(device)
    z0 = epsilon * torch.exp(.5 * qz0_logvar) + qz0_mean
    orig_ts = checkpoint['orig_ts']
    #orig_ts = torch.from_numpy(orig_ts).float().to(device)

with torch.no_grad():
  pred_z = odeint(func, z0, samp_ts).permute(1, 0, 2)
  pred_x = dec(pred_z)
  rmse = torch.mean(torch.sqrt(torch.mean(torch.sum((pred_x - samp_trajs) ** 2, axis=2), axis=1)))
  print(rmse)

zz = z0.cpu().numpy()
#zz = qz0_mean.cpu().numpy()
#zz = qz0_logvar.cpu().numpy()
plt.scatter(zz[:,0], zz[:,1])

import numpy as np
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca.fit(zz)
z2 = pca.fit_transform(zz)
plt.scatter(z2[:,0], z2[:,1])

# take first trajectory for visualization
rmse = []
with torch.no_grad():
  for itr in range(1):
      i = itr
      z0 = z0[i]

      ts_pos = np.linspace(0., 4. * np.pi, num=2000)
      ts_neg = np.linspace(-4*np.pi, 0., num=2000)[::-1].copy()
      ts_pos = torch.from_numpy(ts_pos).float().to(device)
      ts_neg = torch.from_numpy(ts_neg).float().to(device)

      zs_pos = odeint(func, z0, ts_pos)
      zs_neg = odeint(func, z0, ts_neg)

      xs_pos = dec(zs_pos)
      xs_neg = torch.flip(dec(zs_neg), dims=[0])

  xs_pos = xs_pos.cpu().numpy()
  xs_neg = xs_neg.cpu().numpy()
  orig_traj = orig_trajs[i].cpu().numpy()
  samp_traj = samp_trajs[i].cpu().numpy()

  plt.figure()
  plt.plot(orig_traj[:, 0], orig_traj[:, 1],
          'g', label='true trajectory')
  plt.plot(xs_pos[:, 0], xs_pos[:, 1], 'r',
          label='learned trajectory (t>0)')
  plt.plot(xs_neg[:, 0], xs_neg[:, 1], 'b',
          label='learned trajectory (t<0)')
  plt.scatter(samp_traj[:, 0], samp_traj[
              :, 1], label='sampled data', s=3)
  plt.legend(loc='upper right')

orig_ts
samp_ts

samp_traj.shape

zz = z0.cpu().numpy()
#zz = qz0_mean.cpu().numpy()
#zz = qz0_logvar.cpu().numpy()
plt.scatter(zz[:,0], zz[:,1])

zz



# variational generation
plt.figure(figsize=(15,10))
for itr in range(1, 7):
    with torch.no_grad():
        z0 = torch.randn(2).to(device)        
        ts_pos = np.linspace(0., 2. * np.pi, num=2000)
        ts_neg = np.linspace(-np.pi, 0., num=2000)[::-1].copy()
        ts_pos = torch.from_numpy(ts_pos).float().to(device)
        ts_neg = torch.from_numpy(ts_neg).float().to(device)

        zs_pos = odeint(func, z0, ts_pos)
        zs_neg = odeint(func, z0, ts_neg)

        xs_pos = dec(zs_pos)
        xs_neg = torch.flip(dec(zs_neg), dims=[0])

    xs_pos = xs_pos.cpu().numpy()
    xs_neg = xs_neg.cpu().numpy()
    orig_traj = orig_trajs[0].cpu().numpy()
    samp_traj = samp_trajs[0].cpu().numpy()

    plt.subplot(2, 3, itr)
    plt.plot(xs_pos[:, 0], xs_pos[:, 1], 'r',
             label='generated trajectory (t>0)')
    plt.plot(xs_neg[:, 0], xs_neg[:, 1], 'b',
             label='generated trajectory (t<0)')
    plt.legend()

#%%
import torch
import torch.optim as optim

optimizer = optim.SGD([torch.rand((2,2), requires_grad=True)], lr=0.1)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

for epoch in range(1, 21):
    #scheduler.step()
    print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))
    if epoch % 5 == 0:print()    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
